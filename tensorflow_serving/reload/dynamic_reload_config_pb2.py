# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: dynamic_reload_config.proto

import sys
_b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
from google.protobuf import descriptor_pb2
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


import model_server_config_pb2 as model__server__config__pb2


DESCRIPTOR = _descriptor.FileDescriptor(
  name='dynamic_reload_config.proto',
  package='tensorflow.serving',
  syntax='proto3',
  serialized_pb=_b('\n\x1b\x64ynamic_reload_config.proto\x12\x12tensorflow.serving\x1a\x19model_server_config.proto\"\'\n\x0eReloadResponse\x12\x15\n\rreload_status\x18\x01 \x01(\t2o\n\x11PredictionService\x12Z\n\rDynamicReload\x12%.tensorflow.serving.ModelServerConfig\x1a\".tensorflow.serving.ReloadResponseB\x03\xf8\x01\x01\x62\x06proto3')
  ,
  dependencies=[model__server__config__pb2.DESCRIPTOR,])




_RELOADRESPONSE = _descriptor.Descriptor(
  name='ReloadResponse',
  full_name='tensorflow.serving.ReloadResponse',
  filename=None,
  file=DESCRIPTOR,
  containing_type=None,
  fields=[
    _descriptor.FieldDescriptor(
      name='reload_status', full_name='tensorflow.serving.ReloadResponse.reload_status', index=0,
      number=1, type=9, cpp_type=9, label=1,
      has_default_value=False, default_value=_b("").decode('utf-8'),
      message_type=None, enum_type=None, containing_type=None,
      is_extension=False, extension_scope=None,
      options=None),
  ],
  extensions=[
  ],
  nested_types=[],
  enum_types=[
  ],
  options=None,
  is_extendable=False,
  syntax='proto3',
  extension_ranges=[],
  oneofs=[
  ],
  serialized_start=78,
  serialized_end=117,
)

DESCRIPTOR.message_types_by_name['ReloadResponse'] = _RELOADRESPONSE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

ReloadResponse = _reflection.GeneratedProtocolMessageType('ReloadResponse', (_message.Message,), dict(
  DESCRIPTOR = _RELOADRESPONSE,
  __module__ = 'dynamic_reload_config_pb2'
  # @@protoc_insertion_point(class_scope:tensorflow.serving.ReloadResponse)
  ))
_sym_db.RegisterMessage(ReloadResponse)


DESCRIPTOR.has_options = True
DESCRIPTOR._options = _descriptor._ParseOptions(descriptor_pb2.FileOptions(), _b('\370\001\001'))

_PREDICTIONSERVICE = _descriptor.ServiceDescriptor(
  name='PredictionService',
  full_name='tensorflow.serving.PredictionService',
  file=DESCRIPTOR,
  index=0,
  options=None,
  serialized_start=119,
  serialized_end=230,
  methods=[
  _descriptor.MethodDescriptor(
    name='DynamicReload',
    full_name='tensorflow.serving.PredictionService.DynamicReload',
    index=0,
    containing_service=None,
    input_type=model__server__config__pb2._MODELSERVERCONFIG,
    output_type=_RELOADRESPONSE,
    options=None,
  ),
])
_sym_db.RegisterServiceDescriptor(_PREDICTIONSERVICE)

DESCRIPTOR.services_by_name['PredictionService'] = _PREDICTIONSERVICE

try:
  # THESE ELEMENTS WILL BE DEPRECATED.
  # Please use the generated *_pb2_grpc.py files instead.
  import grpc
  from grpc.beta import implementations as beta_implementations
  from grpc.beta import interfaces as beta_interfaces
  from grpc.framework.common import cardinality
  from grpc.framework.interfaces.face import utilities as face_utilities


  class PredictionServiceStub(object):
    """open source marker; do not remove

    """

    def __init__(self, channel):
      """Constructor.

      Args:
        channel: A grpc.Channel.
      """
      self.DynamicReload = channel.unary_unary(
          '/tensorflow.serving.PredictionService/DynamicReload',
          request_serializer=model__server__config__pb2.ModelServerConfig.SerializeToString,
          response_deserializer=ReloadResponse.FromString,
          )


  class PredictionServiceServicer(object):
    """open source marker; do not remove

    """

    def DynamicReload(self, request, context):
      """DynamicReload  --Dynamically reloads modesl from config.
      """
      context.set_code(grpc.StatusCode.UNIMPLEMENTED)
      context.set_details('Method not implemented!')
      raise NotImplementedError('Method not implemented!')


  def add_PredictionServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
        'DynamicReload': grpc.unary_unary_rpc_method_handler(
            servicer.DynamicReload,
            request_deserializer=model__server__config__pb2.ModelServerConfig.FromString,
            response_serializer=ReloadResponse.SerializeToString,
        ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
        'tensorflow.serving.PredictionService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


  class BetaPredictionServiceServicer(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """open source marker; do not remove

    """
    def DynamicReload(self, request, context):
      """DynamicReload  --Dynamically reloads modesl from config.
      """
      context.code(beta_interfaces.StatusCode.UNIMPLEMENTED)


  class BetaPredictionServiceStub(object):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This class was generated
    only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0."""
    """open source marker; do not remove

    """
    def DynamicReload(self, request, timeout, metadata=None, with_call=False, protocol_options=None):
      """DynamicReload  --Dynamically reloads modesl from config.
      """
      raise NotImplementedError()
    DynamicReload.future = None


  def beta_create_PredictionService_server(servicer, pool=None, pool_size=None, default_timeout=None, maximum_timeout=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_deserializers = {
      ('tensorflow.serving.PredictionService', 'DynamicReload'): model__server__config__pb2.ModelServerConfig.FromString,
    }
    response_serializers = {
      ('tensorflow.serving.PredictionService', 'DynamicReload'): ReloadResponse.SerializeToString,
    }
    method_implementations = {
      ('tensorflow.serving.PredictionService', 'DynamicReload'): face_utilities.unary_unary_inline(servicer.DynamicReload),
    }
    server_options = beta_implementations.server_options(request_deserializers=request_deserializers, response_serializers=response_serializers, thread_pool=pool, thread_pool_size=pool_size, default_timeout=default_timeout, maximum_timeout=maximum_timeout)
    return beta_implementations.server(method_implementations, options=server_options)


  def beta_create_PredictionService_stub(channel, host=None, metadata_transformer=None, pool=None, pool_size=None):
    """The Beta API is deprecated for 0.15.0 and later.

    It is recommended to use the GA API (classes and functions in this
    file not marked beta) for all further purposes. This function was
    generated only to ease transition from grpcio<0.15.0 to grpcio>=0.15.0"""
    request_serializers = {
      ('tensorflow.serving.PredictionService', 'DynamicReload'): model__server__config__pb2.ModelServerConfig.SerializeToString,
    }
    response_deserializers = {
      ('tensorflow.serving.PredictionService', 'DynamicReload'): ReloadResponse.FromString,
    }
    cardinalities = {
      'DynamicReload': cardinality.Cardinality.UNARY_UNARY,
    }
    stub_options = beta_implementations.stub_options(host=host, metadata_transformer=metadata_transformer, request_serializers=request_serializers, response_deserializers=response_deserializers, thread_pool=pool, thread_pool_size=pool_size)
    return beta_implementations.dynamic_stub(channel, 'tensorflow.serving.PredictionService', cardinalities, options=stub_options)
except ImportError:
  pass
# @@protoc_insertion_point(module_scope)
